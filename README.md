# ðŸš€ AI/ML Model Deployment on AWS

Deploy machine learning models as scalable APIs using AWS serverless technologies. This project demonstrates a production-ready pipeline for hosting, serving, and maintaining ML models in the cloud.

## ðŸ”§ Tech Stack

| Service          | Purpose                          |
|------------------|----------------------------------|
| **Amazon SageMaker** | Model training and hosting       |
| **AWS Lambda**      | Serverless inference layer       |
| **API Gateway**     | REST API endpoint for predictions|
| **Amazon S3**       | Model artifact storage           |
| **SageMaker Pipelines** | Automated model retraining     |

## âœ¨ Key Features

âœ… **End-to-end ML deployment pipeline**  
âœ… **Scalable serverless architecture**  
âœ… **Automated model updates**  
âœ… **Secure REST API endpoints**  
âœ… **Cost-effective inference**  

## ðŸ“‚ Project Structure
aws-ml-model-deployment/
â”œâ”€â”€ infrastructure/
â”‚ â”œâ”€â”€ sagemaker_model.yml # SageMaker CF template
â”‚ â”œâ”€â”€ api_gateway.yml # API Gateway config
â”‚ â””â”€â”€ lambda_inference.yml # Lambda deployment
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ model/ # Training code
â”‚ â”‚ â”œâ”€â”€ train.py
â”‚ â”‚ â”œâ”€â”€ requirements.txt
â”‚ â”‚ â””â”€â”€ deploy_model.py
â”‚ â”œâ”€â”€ lambda/ # Inference code
â”‚ â”‚ â”œâ”€â”€ inference.py
â”‚ â”‚ â””â”€â”€ requirements.txt
â”‚ â””â”€â”€ scripts/ # Deployment scripts
â”‚ â”œâ”€â”€ deploy.sh
â”‚ â””â”€â”€ update_model.sh
â”œâ”€â”€ docs/
â”‚ â”œâ”€â”€ architecture.md # System design
â”‚ â””â”€â”€ api_spec.md # API documentation
â””â”€â”€ README.md


## ðŸ› ï¸ Deployment Guide

### Prerequisites
- AWS Account with admin permissions
- AWS CLI configured
- Python 3.8+
- Trained ML model (or use our sample)

ðŸ—ï¸ Architecture Overview
graph TD
    A[Client] --> B[API Gateway]
    B --> C[Lambda]
    C --> D[SageMaker Endpoint]
    D --> E[ML Model]
    F[S3 Bucket] --> E
    G[SageMaker Pipeline] --> F

ðŸ§© What You've Built
Component	Description
SageMaker Model	Hosts trained ML model with auto-scaling
Lambda Function	Processes requests and manages inference
API Gateway	Secure HTTPS endpoint for predictions
SageMaker Pipelines	Automated retraining workflow

### 1. Deploy Infrastructure
```bash
./src/scripts/deploy.sh